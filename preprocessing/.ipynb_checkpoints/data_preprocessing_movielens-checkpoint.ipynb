{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daab0449-0bd4-4dec-9b67-422876d45b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "661499ed-028c-4e45-b42f-391f445b9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def check_k_core(dataframe, user_core, item_core):\n",
    "    user_count = defaultdict(int)\n",
    "    item_count = defaultdict(int)\n",
    "    for user in dataframe['uid'].tolist():\n",
    "        user_count[user] += 1\n",
    "    for item in dataframe['iid'].tolist():\n",
    "        item_count[item] += 1\n",
    "    for user in user_count:\n",
    "        if user_count[user] < user_core:\n",
    "            return user_count, item_count, False\n",
    "        \n",
    "    for item in item_count:\n",
    "        if item_count[item] < item_core:\n",
    "            return user_count, item_count, False\n",
    "        \n",
    "    return user_count, item_count, True\n",
    "\n",
    "def delete_users_from_df(dataframe, user_list):\n",
    "    dataframe = dataframe.drop(dataframe[dataframe['uid'].isin(user_list)].index).reset_index(drop=True)\n",
    "    return dataframe\n",
    "\n",
    "def delete_items_from_df(dataframe, item_list):\n",
    "    dataframe = dataframe.drop(dataframe[dataframe['iid'].isin(item_list)].index).reset_index(drop=True)\n",
    "    return dataframe\n",
    "\n",
    "def filter_k_core(dataframe, user_core, item_core):\n",
    "    user_count, item_count, isKcore = check_k_core(dataframe, user_core, item_core)\n",
    "    while not isKcore:\n",
    "        delete_user_list = [user for user in user_count if user_count[user] < user_core]\n",
    "        delete_item_list = [item for item in item_count if item_count[item] < item_core]\n",
    "        dataframe = delete_users_from_df(dataframe, delete_user_list)\n",
    "        dataframe = delete_items_from_df(dataframe, delete_item_list)\n",
    "        \n",
    "        user_count, item_count, isKcore = check_k_core(dataframe, user_core, item_core)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d25bb619-7f15-4945-807c-564d1c8e7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_name(raw_data_name):\n",
    "    if raw_data_name == 'ml-100k':\n",
    "        return 'ML100K'\n",
    "    elif raw_data_name == 'ml-1m':\n",
    "        return 'ML1M'\n",
    "    elif raw_data_name == 'ml-20m':\n",
    "        return 'ML20M'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "def load_data(raw_data_folder, raw_data_name, user_core, item_core):\n",
    "    if raw_data_name == 'ml-1m':\n",
    "        raw_data_path = os.path.join(raw_data_folder, raw_data_name, 'ratings.dat')\n",
    "        sep = \"::\"\n",
    "        skipr = 0\n",
    "    elif raw_data_name == 'ml-20m':\n",
    "        raw_data_path = os.path.join(raw_data_folder, raw_data_name, 'ratings.csv')\n",
    "        sep = ','\n",
    "        skipr = 1\n",
    "    elif raw_data_name == 'ml-100k':\n",
    "        raw_data_path = os.path.join(raw_data_folder, raw_data_name, 'u.data')\n",
    "        sep = \"\\t\"\n",
    "        skipr = 0\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    if not os.path.exists(raw_data_path):\n",
    "        raise FileNotFoundError\n",
    "    name_cols = ['uid', 'iid', 'rating', 'timestamp'] \n",
    "    print(f'load data from {raw_data_name} dataset')\n",
    "    df = pd.read_csv(raw_data_path, names = name_cols, sep=sep, skiprows=skipr)\n",
    "    print(f'apply user {user_core} core and item {item_core} core filters')\n",
    "    df = filter_k_core(df, user_core, item_core)\n",
    "    df = df.sort_values('timestamp')\n",
    "    users = df['uid'].tolist()\n",
    "    items = df['iid'].tolist()\n",
    "    user_num = len(df['uid'].unique())\n",
    "    item_num = len(df['iid'].unique())\n",
    "    print(f'The {raw_data_name} dataset has {len(users)} data with {user_num} users and {item_num} items')\n",
    "    assert len(users) == len(items)\n",
    "    user_sequence = defaultdict(list)\n",
    "    for i in range(len(users)):\n",
    "        user = str(users[i])\n",
    "        item = str(items[i])\n",
    "        user_sequence[user].append(item)\n",
    "    return user_sequence\n",
    "\n",
    "def write_sequence_into_file(data_path, raw_data_name, user_sequence):\n",
    "    data_name = get_data_name(raw_data_name)\n",
    "    data_folder = os.path.join(data_path,data_name)\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    data_file = os.path.join(data_folder, 'user_sequence.txt')\n",
    "    with open(data_file, 'w') as out:\n",
    "        for user, items in user_sequence.items():\n",
    "            out.write(user + ' ' + ' '.join(items) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccc8d4b8-dc87-4276-ade6-495f32fbf09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ml-1m dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2601462/4198305261.py:30: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(raw_data_path, names = name_cols, sep=sep, skiprows=skipr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply user 5 core and item 5 core filters\n",
      "The ml-1m dataset has 999611 data with 6040 users and 3416 items\n"
     ]
    }
   ],
   "source": [
    "raw_data_folder = '../raw_data/MovieLens/'\n",
    "raw_data_name = 'ml-1m'\n",
    "data_path = '../data/'\n",
    "user_sequence = load_data(raw_data_folder, raw_data_name, 5, 5)\n",
    "write_sequence_into_file(data_path, raw_data_name, user_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d4a1812-59ad-4e83-b148-12b4268903ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ml-100k dataset\n",
      "apply user 5 core and item 5 core filters\n",
      "The ml-100k dataset has 99287 data with 943 users and 1349 items\n"
     ]
    }
   ],
   "source": [
    "raw_data_folder = '../raw_data/MovieLens/'\n",
    "raw_data_name = 'ml-100k'\n",
    "data_path = '../data/'\n",
    "user_sequence = load_data(raw_data_folder, raw_data_name, 5, 5)\n",
    "write_sequence_into_file(data_path, raw_data_name, user_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89f8f80f-e8b6-4124-aa52-5dbb19d4a54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ml-20m dataset\n",
      "apply user 5 core and item 5 core filters\n",
      "The ml-20m dataset has 19984024 data with 138493 users and 18345 items\n"
     ]
    }
   ],
   "source": [
    "raw_data_folder = '../raw_data/MovieLens/'\n",
    "raw_data_name = 'ml-20m'\n",
    "data_path = '../data/'\n",
    "user_sequence = load_data(raw_data_folder, raw_data_name, 5, 5)\n",
    "write_sequence_into_file(data_path, raw_data_name, user_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d1d2c72-6096-4738-9672-8484a27ac5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99287"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_folder = '../raw_data/MovieLens/'\n",
    "raw_data_name = 'ml-100k'\n",
    "raw_data_path = os.path.join(raw_data_folder, raw_data_name, 'u.data')\n",
    "name_cols = ['uid', 'iid', 'rating', 'timestamp'] \n",
    "df = pd.read_csv(raw_data_path, names = name_cols, skiprows=0, sep=\"\\t\")\n",
    "df = filter_k_core(df, 5, 5)\n",
    "len(df['uid'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a0055-d1ac-4a96-9c87-2e647a4c7ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP5",
   "language": "python",
   "name": "sp5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
